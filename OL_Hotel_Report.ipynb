{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd3Qm3naTCHhPSaxxPlbsC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidGTeklea/BigIdeasFinal/blob/main/OL_Hotel_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsg1xjvgjgJM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8RiByDhb92c",
        "outputId": "1540f505-39a8-4c87-ae84-75c314699696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n"
          ]
        }
      ],
      "source": [
        "pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "yd9fTt058K2s",
        "outputId": "499e4fbe-5a29-44ed-ac79-9d5428ccecdb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e618e1c-9f75-4080-90d2-cf09e01ceea3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e618e1c-9f75-4080-90d2-cf09e01ceea3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"davidteklea\",\"key\":\"6979f4292245affec7e1edf13a2bb74f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ],
      "metadata": {
        "id": "xIX9HDMa8LGf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!kaggle datasets download -d jessemostipak/hotel-booking-demand -p data/\n",
        "!unzip data/hotel-booking-demand.zip -d data/\n"
      ],
      "metadata": {
        "id": "qR6n7oyCcGAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf00cc7-53aa-4a7c-b705-319e19bc7c36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Dataset URL: https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading hotel-booking-demand.zip to data\n",
            "  0% 0.00/1.25M [00:00<?, ?B/s]\n",
            "100% 1.25M/1.25M [00:00<00:00, 512MB/s]\n",
            "Archive:  data/hotel-booking-demand.zip\n",
            "  inflating: data/hotel_bookings.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, torch\n",
        "def set_seed(s=2025):\n",
        "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
        "set_seed(2025)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "GqYWNhsju2yv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# Individual Time-Aware Split → Shared Preprocess\n",
        "# (low-card OHE, high-card CountEncoding, StandardScaler, float32)\n",
        "# ================================================================\n",
        "# python >=3.10\n",
        "# pip install scikit-learn>=1.2 category-encoders pandas numpy joblib matplotlib\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import os, time, pathlib, multiprocessing as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import category_encoders as ce\n",
        "from joblib import Memory\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.base import clone\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "\n",
        "# ---------- CPU settings ----------\n",
        "NJOBS = min(2, mp.cpu_count() or 2)\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(NJOBS)\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(NJOBS)\n",
        "os.environ[\"MKL_NUM_THREADS\"] = str(NJOBS)\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(NJOBS)\n",
        "\n",
        "# ---------- Config ----------\n",
        "CSV_PATH   = \"data/hotel_bookings.csv\"\n",
        "TARGET     = \"is_canceled\"\n",
        "TIME_COL   = \"_t\"                  # helper booking timestamp (for splitting only)\n",
        "TEST_SIZE  = 0.20\n",
        "SEED_SPLIT = 2025\n",
        "\n",
        "# leakage drops (at-booking model)\n",
        "DROP_ALWAYS = [\"reservation_status\", \"reservation_status_date\"]\n",
        "# You can add more here later after EDA:\n",
        "DROP_OPTIONAL = []  # e.g., [\"booking_changes\",\"days_in_waiting_list\"]\n",
        "\n",
        "# high-cardinality cutoff and encoder settings\n",
        "HICARD_THRESH = 50\n",
        "COUNT_NORMALIZE = True  # frequency (0..1)\n",
        "\n",
        "# output/cache\n",
        "BASE_OUT = pathlib.Path(\"results/shared_pipeline_time_individual\")\n",
        "BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
        "CACHE_DIR = pathlib.Path(\"cache_shared\")\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "memory = Memory(location=str(CACHE_DIR), verbose=0)\n",
        "\n",
        "# ---------- Load ----------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df = df.drop(columns=[c for c in DROP_ALWAYS + DROP_OPTIONAL if c in df.columns]).copy()\n",
        "\n",
        "# ---------- Build booking_time = arrival_date - lead_time ----------\n",
        "def build_booking_time(d: pd.DataFrame) -> pd.Series:\n",
        "    # robust to month names\n",
        "    arr = pd.to_datetime(\n",
        "        d[\"arrival_date_year\"].astype(str) + \"-\" +\n",
        "        d[\"arrival_date_month\"].astype(str) + \"-\" +\n",
        "        d[\"arrival_date_day_of_month\"].astype(str),\n",
        "        errors=\"coerce\"\n",
        "    )\n",
        "    lead = pd.to_timedelta(d[\"lead_time\"].fillna(0).astype(int), unit=\"D\")\n",
        "    t = arr - lead                               # booking time (at booking)\n",
        "    if t.isna().all():\n",
        "        t = arr                                  # fallback to arrival\n",
        "    t = t.fillna(t.dropna().min())               # fill any remaining NaT\n",
        "    return t\n",
        "\n",
        "\n",
        "df[TIME_COL] = build_booking_time(df)\n",
        "min_ts = df[TIME_COL].dropna().min()\n",
        "df[TIME_COL] = df[TIME_COL].fillna(min_ts)\n",
        "\n",
        "\n",
        "# Add after df[TIME_COL] is created:\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET].values\n",
        "# Time-based split\n",
        "split_time = X[TIME_COL].quantile(1 - TEST_SIZE)\n",
        "train_mask = X[TIME_COL] <= split_time\n",
        "X_train = X[train_mask].copy()\n",
        "X_test = X[~train_mask].copy()\n",
        "y_train = y[train_mask]\n",
        "y_test = y[~train_mask]\n",
        "w_train = compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=y_train\n",
        ")\n",
        "# ---------- Sort TRAIN chronologically for TimeSeriesSplit ----------\n",
        "\n",
        "\n",
        "ord_tr = X_train[TIME_COL].argsort(kind=\"mergesort\")\n",
        "X_train = X_train.iloc[ord_tr].reset_index(drop=True)\n",
        "y_train = y_train[ord_tr]\n",
        "w_train = w_train[ord_tr]\n",
        "\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# Shared preprocessing\n",
        "#  - Exclude TIME_COL from features (split helper; seasonality should come from arrival parts)\n",
        "#  - numeric: impute → (global) StandardScaler(with_mean=False)\n",
        "#  - categorical low-card: OHE (sparse)\n",
        "#  - categorical high-card: CountEncoder (dense) → CSR\n",
        "#  - cast to float32\n",
        "# ================================================================\n",
        "def dense_to_csr(X):\n",
        "    if sp.issparse(X): return X.tocsr()\n",
        "    return sp.csr_matrix(X)\n",
        "\n",
        "def to_dense(X):\n",
        "    import numpy as np, scipy.sparse as sp\n",
        "    return X.toarray() if sp.issparse(X) else np.asarray(X)\n",
        "\n",
        "def to_float32(X):\n",
        "    import numpy as np, scipy.sparse as sp\n",
        "    if sp.issparse(X): return X.astype(np.float32)\n",
        "    return np.asarray(X, dtype=np.float32, copy=False)\n",
        "\n",
        "def make_shared_preprocess(X_frame: pd.DataFrame, memory=None):\n",
        "    Xf = X_frame.drop(columns=[TIME_COL], errors=\"ignore\")\n",
        "    cat_cols = [c for c in Xf.columns if Xf[c].dtype == \"object\"]\n",
        "    num_cols = [c for c in Xf.columns if c not in cat_cols]\n",
        "\n",
        "    nunique = {c: Xf[c].nunique(dropna=True) for c in cat_cols}\n",
        "    cat_low = [c for c in cat_cols if nunique[c] <= HICARD_THRESH]\n",
        "    cat_hi  = [c for c in cat_cols if nunique[c] >  HICARD_THRESH]\n",
        "\n",
        "    num_pipe = Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\",  StandardScaler()),\n",
        "    ], memory=memory)  # <- no caching\n",
        "\n",
        "    low_pipe = Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\",\n",
        "                              sparse_output=True, dtype=np.float32)),\n",
        "    ], memory=memory)  # <- no caching\n",
        "\n",
        "    # No csr step; keep it dense here, union stays sparse due to OHE + sparse_threshold\n",
        "    hi_pipe = Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"cnt\", ce.CountEncoder(normalize=COUNT_NORMALIZE)),\n",
        "        (\"sc\",  StandardScaler()),\n",
        "    ], memory=memory)  # <- no caching\n",
        "\n",
        "    preprocess = ColumnTransformer([\n",
        "        (\"num\",     num_pipe, num_cols),\n",
        "        (\"cat_low\", low_pipe, cat_low),\n",
        "        (\"cat_hi\",  hi_pipe,  cat_hi),\n",
        "    ], remainder=\"drop\", sparse_threshold=1.0, n_jobs=None)  # <- no n_jobs inside\n",
        "\n",
        "    shared = Pipeline([\n",
        "        (\"prep\",  preprocess),\n",
        "        (\"fp32\",  FunctionTransformer(to_float32, accept_sparse=True, validate=False)),\n",
        "    ], memory=memory)  # <- no caching\n",
        "\n",
        "    return shared\n",
        "\n",
        "def add_densify(shared_pipeline):\n",
        "    steps = list(shared_pipeline.steps) + [\n",
        "        (\"dense\", FunctionTransformer(to_dense, accept_sparse=True, validate=False)),\n",
        "        (\"fp32b\", FunctionTransformer(to_float32, accept_sparse=False, validate=False)),\n",
        "    ]\n",
        "    return Pipeline(steps, memory=memory)  # <- no caching\n",
        "\n",
        "shared_pre = make_shared_preprocess(X_train, memory)\n",
        "\n",
        "# 1) Fit a *throwaway* copy of your preprocessor just to read its width. for rbf\n",
        "tmp_pre = make_shared_preprocess(X_train)\n",
        "tmp_pre.fit(X_train)                           # train-split only; no leakage to test\n",
        "d = tmp_pre.transform(X_train.iloc[:1]).shape[1]\n",
        "print(d)\n",
        "\n",
        "\n",
        "# ---------- Time-aware CV (individual, forward-chaining) ----------\n",
        "INNER_SPLITS = 3\n",
        "INNER_CV = TimeSeriesSplit(n_splits=INNER_SPLITS)\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix\n",
        "\n",
        "def choose_threshold_max_f1(y_true, scores, pos_label=1):\n",
        "    \"\"\"Return t*, best_F1, precision_at_t*, recall_at_t* using decision_function scores.\"\"\"\n",
        "    P, R, T = precision_recall_curve(y_true, scores, pos_label=pos_label)\n",
        "    # precision_recall_curve returns len(T) = len(P) - 1 = len(R) - 1\n",
        "    f1 = 2 * P[1:] * R[1:] / (P[1:] + R[1:] + 1e-12)\n",
        "    i = np.nanargmax(f1)\n",
        "    return T[i], float(f1[i]), float(P[i+1]), float(R[i+1])\n",
        "\n",
        "def apply_threshold(scores, t_star):\n",
        "    return (scores >= t_star).astype(int)\n",
        "\n",
        "TAUS = globals().get(\"TAUS\", {})\n",
        "\n"
      ],
      "metadata": {
        "id": "mstZNSNE2744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40c6870-9c39-4158-9467-ee4e1099ec02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "id": "tVmAhC6E4ke6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf574070-585f-45a2-de13-aad7b362c19c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from skorch) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (1.16.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->skorch) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n",
            "Downloading skorch-1.2.0-py3-none-any.whl (263 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/263.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m256.0/263.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: skorch\n",
            "Successfully installed skorch-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Make a chronological validation split *inside your training period*\n",
        "VAL_SIZE = 0.20\n",
        "cut = X_train[TIME_COL].quantile(1 - VAL_SIZE)\n",
        "\n",
        "tr_mask  = X_train[TIME_COL] <= cut      # earlier 80% -> model-fitting \"train\"\n",
        "val_mask = ~tr_mask                      # later 20%  -> fixed \"validation\"\n",
        "\n",
        "X_tr_df  = X_train.loc[tr_mask].copy()\n",
        "y_tr     = y_train[tr_mask]\n",
        "X_val_df = X_train.loc[val_mask].copy()\n",
        "y_val    = y_train[val_mask]\n",
        "\n",
        "# 2) Fit your existing preprocessor on TRAIN ONLY (no leakage)\n",
        "shared_pre = make_shared_preprocess(X_tr_df, memory=None)\n",
        "shared_pre.fit(X_tr_df)                  # <— this is what I meant by \"shared_pre_fit\"\n",
        "\n",
        "# 3) Transform to numpy (float32). If sparse, densify before tensors.\n",
        "import numpy as np, scipy.sparse as sp\n",
        "def to_dense_np(X):\n",
        "    return X.toarray().astype(np.float32) if sp.issparse(X) else np.asarray(X, np.float32)\n",
        "\n",
        "X_tr_np  = to_dense_np(shared_pre.transform(X_tr_df))\n",
        "X_val_np = to_dense_np(shared_pre.transform(X_val_df))\n",
        "X_te_np  = to_dense_np(shared_pre.transform(X_test.copy()))\n",
        "y_tr_np  = y_tr.astype(np.float32)\n",
        "y_val_np = y_val.astype(np.float32)\n",
        "y_te_np  = y_test.astype(np.float32)\n",
        "\n",
        "tr = torch.from_numpy(X_tr_np).float();\n",
        "ytr = torch.from_numpy(y_tr_np).float();\n",
        "\n",
        "# --- continue from your last line ---\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 4) Convert to tensors (binary classification → float targets)\n",
        "Xtr_t  = torch.from_numpy(X_tr_np).float()\n",
        "Xval_t = torch.from_numpy(X_val_np).float()\n",
        "Xte_t  = torch.from_numpy(X_te_np).float()\n",
        "\n",
        "ytr_t  = torch.from_numpy(y_tr_np).float()   # 0/1 as float for BCEWithLogitsLoss\n",
        "yval_t = torch.from_numpy(y_val_np).float()\n",
        "yte_t  = torch.from_numpy(y_te_np).float()\n",
        "\n",
        "# 5) Wrap into datasets/loaders (shuffle only on training)\n",
        "train_loader = DataLoader(TensorDataset(Xtr_t,  ytr_t),  batch_size=256,  shuffle=True,  drop_last=False)\n",
        "val_loader   = DataLoader(TensorDataset(Xval_t, yval_t), batch_size=1024, shuffle=False)\n",
        "test_loader  = DataLoader(TensorDataset(Xte_t,  yte_t),  batch_size=1024, shuffle=False)\n",
        "\n",
        "# --- quick sanity checks (optional) ---\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"Train batch:\", xb.shape, yb.shape, xb.dtype, yb.dtype)  # e.g., [256, d], [256]\n",
        "print(\"Val size:\", len(val_loader.dataset), \"Test size:\", len(test_loader.dataset))\n",
        "\n"
      ],
      "metadata": {
        "id": "RXjJv6mNqCCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4549542-9900-4602-9cc7-0b225804511a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batch: torch.Size([256, 81]) torch.Size([256]) torch.float32 torch.float32\n",
            "Val size: 19108 Test size: 23703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== MLP (skorch, SGD) — Halving v2 (balanced, faster learning) ===================== #with treshold\n",
        "import numpy as np, torch, torch.nn as nn\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve  # <- added PRC\n",
        "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
        "from sklearn.model_selection import HalvingGridSearchCV, TimeSeriesSplit\n",
        "from sklearn.base import clone  # <- added\n",
        "from skorch import NeuralNetBinaryClassifier\n",
        "from skorch.callbacks import EarlyStopping\n",
        "\n",
        "# imbalance weight (pos_weight = neg/pos)\n",
        "pos = float((y_train == 1).sum())\n",
        "neg = float((y_train == 0).sum())\n",
        "pos_weight = torch.tensor([neg / max(pos, 1.0)], dtype=torch.float32)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden=(512, 512), dropout=0.0):\n",
        "        super().__init__()\n",
        "        layers, lazy, prev = [], True, None\n",
        "        for h in hidden:\n",
        "            layers += [nn.LazyLinear(h) if lazy else nn.Linear(prev, h), nn.ReLU()]\n",
        "            if dropout > 0: layers += [nn.Dropout(dropout)]\n",
        "            prev, lazy = h, False\n",
        "        layers += [nn.Linear(prev, 1)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, X):\n",
        "        return self.net(X).squeeze(-1)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = NeuralNetBinaryClassifier(\n",
        "    module=MLP,\n",
        "    max_epochs=15,\n",
        "    optimizer=torch.optim.SGD,\n",
        "    optimizer__momentum=0.0, optimizer__nesterov=False,\n",
        "    criterion=nn.BCEWithLogitsLoss,\n",
        "    criterion__pos_weight=pos_weight,\n",
        "    batch_size=2048,\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_train__num_workers=0,\n",
        "    iterator_valid__num_workers=0,\n",
        "    iterator_train__pin_memory=False,\n",
        "    iterator_valid__pin_memory=False,\n",
        "    train_split=None,\n",
        "    callbacks=[EarlyStopping(monitor='train_loss', patience=2, threshold=1e-4)],\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "pipe_nn = Pipeline([\n",
        "    (\"pre\", shared_pre),\n",
        "    (\"clf\", net),\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"clf__module__hidden\": [(1024, 128), (216, 216, 216, 216, 216)],\n",
        "    \"clf__optimizer__lr\": [0.1, 0.5, 1],\n",
        "    \"clf__optimizer__weight_decay\": [1e-4, 1e-3],\n",
        "    \"clf__batch_size\": [2048],\n",
        "}\n",
        "\n",
        "n_splits = 3\n",
        "\n",
        "# for just 10,000 rows speed test\n",
        "# X_train = X_train.iloc[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "\n",
        "INNER_CV = TimeSeriesSplit(n_splits=n_splits)\n",
        "N_TRAIN = len(X_train)\n",
        "min_train_fold = max(2048, N_TRAIN // (n_splits + 2))\n",
        "\n",
        "hgrid_nn = HalvingGridSearchCV(\n",
        "    pipe_nn,\n",
        "    param_grid=param_grid,\n",
        "    cv=INNER_CV,\n",
        "    scoring=\"roc_auc\",\n",
        "    resource=\"n_samples\",\n",
        "    factor=4,\n",
        "    min_resources=min_train_fold,\n",
        "    max_resources=N_TRAIN,\n",
        "    aggressive_elimination=True,\n",
        "    n_jobs=1,            # IMPORTANT with skorch\n",
        "    refit=True,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "hgrid_nn.fit(X_train, y_train.astype(np.float32))\n",
        "\n",
        "# ===== Metrics =====\n",
        "def proba(est, X):\n",
        "    p = est.predict_proba(X)\n",
        "    return p.ravel() if p.ndim == 2 and p.shape[1] == 1 else p[:, 1]\n",
        "\n",
        "# ---- pick τ* on LAST fold (time-aware), using predict_proba ----\n",
        "tr_idx, val_idx = list(INNER_CV.split(X_train))[-1]\n",
        "nn_lastfold = clone(hgrid_nn.best_estimator_).fit(X_train.iloc[tr_idx], y_train[tr_idx].astype(np.float32))\n",
        "val_scores = proba(nn_lastfold, X_train.iloc[val_idx])\n",
        "P, R, T = precision_recall_curve(y_train[val_idx], val_scores)\n",
        "F1 = 2 * P * R / (P + R + 1e-12)\n",
        "tau_star = float(T[F1[:-1].argmax()])\n",
        "print(f\"τ* (last-fold, max F1): {tau_star:.4f}\")\n",
        "\n",
        "p_tr = proba(hgrid_nn, X_train)\n",
        "p_te = proba(hgrid_nn, X_test)\n",
        "\n",
        "best_net = hgrid_nn.best_estimator_.named_steps[\"clf\"]\n",
        "param_count = int(sum(p.numel() for p in best_net.module_.parameters() if p.requires_grad))\n",
        "epochs = len(best_net.history_) if hasattr(best_net, \"history_\") else None\n",
        "\n",
        "print(\"\\n=== MLP (skorch, SGD) — Halving v2 ===\")\n",
        "print(\"best params:\", hgrid_nn.best_params_)\n",
        "print(\"param count:\", param_count, \"| epochs:\", epochs)\n",
        "print(\"best CV ROC-AUC:\", round(hgrid_nn.best_score_, 4))\n",
        "print(\"train ROC-AUC:\", round(roc_auc_score(y_train, p_tr), 4))\n",
        "print(\"test  ROC-AUC:\",  round(roc_auc_score(y_test,  p_te), 4))\n",
        "print(\"train acc @τ*:\", round(accuracy_score(y_train, (p_tr >= tau_star).astype(int)), 4))  # <- updated\n",
        "print(\"test  acc @τ*:\",  round(accuracy_score(y_test,  (p_te >= tau_star).astype(int)), 4))  # <- updated\n",
        "print(\"train AP:\", round(average_precision_score(y_train, p_tr), 4))\n",
        "print(\"test  AP:\",  round(average_precision_score(y_test,  p_te), 4))\n",
        "\n",
        "TAUS[\"MLP (SGD)\"]    = tau_star\n"
      ],
      "metadata": {
        "id": "GEpTOE7crvBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8b85a3-2349-48ff-c8a1-9cefbaae1ad3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 2\n",
            "n_required_iterations: 2\n",
            "n_possible_iterations: 2\n",
            "min_resources_: 19137\n",
            "max_resources_: 95687\n",
            "aggressive_elimination: True\n",
            "factor: 4\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 12\n",
            "n_resources: 19137\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8711\u001b[0m  0.8980\n",
            "      2        \u001b[36m0.8444\u001b[0m  0.8702\n",
            "      3        \u001b[36m0.8157\u001b[0m  0.9332\n",
            "      4        \u001b[36m0.7813\u001b[0m  1.3830\n",
            "      5        \u001b[36m0.7399\u001b[0m  1.9075\n",
            "      6        \u001b[36m0.6934\u001b[0m  0.8910\n",
            "      7        \u001b[36m0.6436\u001b[0m  0.3899\n",
            "      8        \u001b[36m0.5947\u001b[0m  0.4688\n",
            "      9        \u001b[36m0.5492\u001b[0m  0.4242\n",
            "     10        \u001b[36m0.5081\u001b[0m  0.4029\n",
            "     11        \u001b[36m0.4726\u001b[0m  0.4722\n",
            "     12        \u001b[36m0.4441\u001b[0m  0.4638\n",
            "     13        \u001b[36m0.4193\u001b[0m  0.4414\n",
            "     14        \u001b[36m0.3995\u001b[0m  0.4382\n",
            "     15        \u001b[36m0.3830\u001b[0m  0.4014\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8453\u001b[0m  0.7879\n",
            "      2        \u001b[36m0.7964\u001b[0m  0.8306\n",
            "      3        \u001b[36m0.7370\u001b[0m  0.8145\n",
            "      4        \u001b[36m0.6687\u001b[0m  0.8120\n",
            "      5        \u001b[36m0.6018\u001b[0m  0.7689\n",
            "      6        \u001b[36m0.5466\u001b[0m  0.8847\n",
            "      7        \u001b[36m0.5049\u001b[0m  1.1917\n",
            "      8        \u001b[36m0.4750\u001b[0m  1.1509\n",
            "      9        \u001b[36m0.4534\u001b[0m  0.8216\n",
            "     10        \u001b[36m0.4369\u001b[0m  0.8261\n",
            "     11        \u001b[36m0.4246\u001b[0m  0.8448\n",
            "     12        \u001b[36m0.4149\u001b[0m  0.9910\n",
            "     13        \u001b[36m0.4061\u001b[0m  0.8750\n",
            "     14        \u001b[36m0.3993\u001b[0m  0.8373\n",
            "     15        \u001b[36m0.3934\u001b[0m  0.8430\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8307\u001b[0m  1.1976\n",
            "      2        \u001b[36m0.7730\u001b[0m  1.1658\n",
            "      3        \u001b[36m0.7072\u001b[0m  1.7254\n",
            "      4        \u001b[36m0.6378\u001b[0m  1.4984\n",
            "      5        \u001b[36m0.5885\u001b[0m  1.2916\n",
            "      6        \u001b[36m0.5456\u001b[0m  1.2065\n",
            "      7        \u001b[36m0.5230\u001b[0m  1.2492\n",
            "      8        \u001b[36m0.5111\u001b[0m  1.2530\n",
            "      9        \u001b[36m0.4897\u001b[0m  1.2253\n",
            "     10        \u001b[36m0.4894\u001b[0m  1.2410\n",
            "     11        \u001b[36m0.4766\u001b[0m  1.2100\n",
            "     12        \u001b[36m0.4738\u001b[0m  1.5065\n",
            "     13        \u001b[36m0.4650\u001b[0m  1.7600\n",
            "     14        \u001b[36m0.4605\u001b[0m  1.1652\n",
            "     15        0.4671  1.2058\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8678\u001b[0m  0.4118\n",
            "      2        \u001b[36m0.8413\u001b[0m  0.4355\n",
            "      3        \u001b[36m0.8127\u001b[0m  0.6911\n",
            "      4        \u001b[36m0.7781\u001b[0m  0.7190\n",
            "      5        \u001b[36m0.7359\u001b[0m  0.4843\n",
            "      6        \u001b[36m0.6879\u001b[0m  0.3992\n",
            "      7        \u001b[36m0.6373\u001b[0m  0.4308\n",
            "      8        \u001b[36m0.5870\u001b[0m  0.4204\n",
            "      9        \u001b[36m0.5410\u001b[0m  0.4102\n",
            "     10        \u001b[36m0.5009\u001b[0m  0.4168\n",
            "     11        \u001b[36m0.4670\u001b[0m  0.4209\n",
            "     12        \u001b[36m0.4381\u001b[0m  0.4498\n",
            "     13        \u001b[36m0.4152\u001b[0m  0.6208\n",
            "     14        \u001b[36m0.3974\u001b[0m  0.5989\n",
            "     15        \u001b[36m0.3819\u001b[0m  0.5899\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8465\u001b[0m  1.5105\n",
            "      2        \u001b[36m0.8033\u001b[0m  1.3472\n",
            "      3        \u001b[36m0.7500\u001b[0m  1.6586\n",
            "      4        \u001b[36m0.6858\u001b[0m  1.6883\n",
            "      5        \u001b[36m0.6196\u001b[0m  1.4865\n",
            "      6        \u001b[36m0.5626\u001b[0m  0.8620\n",
            "      7        \u001b[36m0.5180\u001b[0m  0.8918\n",
            "      8        \u001b[36m0.4853\u001b[0m  1.2479\n",
            "      9        \u001b[36m0.4610\u001b[0m  1.2151\n",
            "     10        \u001b[36m0.4431\u001b[0m  0.8573\n",
            "     11        \u001b[36m0.4295\u001b[0m  0.8297\n",
            "     12        \u001b[36m0.4186\u001b[0m  0.7994\n",
            "     13        \u001b[36m0.4102\u001b[0m  0.8593\n",
            "     14        \u001b[36m0.4036\u001b[0m  0.7802\n",
            "     15        \u001b[36m0.3974\u001b[0m  0.8338\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8432\u001b[0m  1.2162\n",
            "      2        \u001b[36m0.8038\u001b[0m  1.2612\n",
            "      3        \u001b[36m0.7440\u001b[0m  1.2918\n",
            "      4        \u001b[36m0.6729\u001b[0m  1.7741\n",
            "      5        \u001b[36m0.6100\u001b[0m  1.4257\n",
            "      6        \u001b[36m0.5714\u001b[0m  1.2245\n",
            "      7        \u001b[36m0.5476\u001b[0m  1.2015\n",
            "      8        \u001b[36m0.5136\u001b[0m  1.2230\n",
            "      9        \u001b[36m0.4977\u001b[0m  1.2428\n",
            "     10        \u001b[36m0.4834\u001b[0m  1.3205\n",
            "     11        0.4914  1.2786\n",
            "     12        \u001b[36m0.4697\u001b[0m  1.2205\n",
            "     13        0.4697  1.6783\n",
            "     14        \u001b[36m0.4554\u001b[0m  1.6625\n",
            "     15        \u001b[36m0.4552\u001b[0m  1.2575\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8364\u001b[0m  0.4044\n",
            "      2        \u001b[36m0.6466\u001b[0m  0.4378\n",
            "      3        0.8211  0.4601\n",
            "      4        \u001b[36m0.5925\u001b[0m  0.4613\n",
            "      5        \u001b[36m0.4140\u001b[0m  0.3963\n",
            "      6        \u001b[36m0.3448\u001b[0m  0.6581\n",
            "      7        \u001b[36m0.3225\u001b[0m  0.4154\n",
            "      8        0.3571  0.4581\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7902\u001b[0m  0.8723\n",
            "      2        \u001b[36m0.7532\u001b[0m  0.9298\n",
            "      3        \u001b[36m0.6036\u001b[0m  1.1757\n",
            "      4        \u001b[36m0.4392\u001b[0m  1.1620\n",
            "      5        0.4513  0.8812\n",
            "      6        \u001b[36m0.4163\u001b[0m  1.0626\n",
            "      7        \u001b[36m0.3871\u001b[0m  1.7739\n",
            "      8        0.3939  1.6322\n",
            "      9        \u001b[36m0.3844\u001b[0m  1.6721\n",
            "     10        \u001b[36m0.3603\u001b[0m  1.4864\n",
            "     11        \u001b[36m0.3454\u001b[0m  2.6564\n",
            "     12        0.3467  2.4086\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7688\u001b[0m  1.1965\n",
            "      2        \u001b[36m0.7151\u001b[0m  1.1837\n",
            "      3        \u001b[36m0.5578\u001b[0m  1.2147\n",
            "      4        0.7044  1.2533\n",
            "      5        \u001b[36m0.4683\u001b[0m  1.2007\n",
            "      6        0.5282  1.6333\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8411\u001b[0m  0.3924\n",
            "      2        \u001b[36m0.6590\u001b[0m  0.5080\n",
            "      3        \u001b[36m0.6513\u001b[0m  0.4994\n",
            "      4        0.7421  0.4379\n",
            "      5        \u001b[36m0.5317\u001b[0m  0.4717\n",
            "      6        \u001b[36m0.4158\u001b[0m  0.4713\n",
            "      7        \u001b[36m0.3437\u001b[0m  0.5129\n",
            "      8        \u001b[36m0.3170\u001b[0m  0.4604\n",
            "      9        0.3675  0.4776\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7817\u001b[0m  0.8386\n",
            "      2        \u001b[36m0.7307\u001b[0m  0.8856\n",
            "      3        \u001b[36m0.5335\u001b[0m  1.1922\n",
            "      4        \u001b[36m0.4284\u001b[0m  1.2147\n",
            "      5        \u001b[36m0.4023\u001b[0m  0.9596\n",
            "      6        0.5807  0.8285\n",
            "      7        \u001b[36m0.3869\u001b[0m  0.8912\n",
            "      8        \u001b[36m0.3690\u001b[0m  0.8858\n",
            "      9        \u001b[36m0.3644\u001b[0m  0.8341\n",
            "     10        \u001b[36m0.3527\u001b[0m  0.8171\n",
            "     11        \u001b[36m0.3495\u001b[0m  0.8640\n",
            "     12        0.3804  0.8379\n",
            "     13        \u001b[36m0.3308\u001b[0m  0.8407\n",
            "     14        0.3500  0.8438\n",
            "     15        \u001b[36m0.3292\u001b[0m  0.8069\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7660\u001b[0m  1.8149\n",
            "      2        \u001b[36m0.7320\u001b[0m  1.2340\n",
            "      3        \u001b[36m0.5525\u001b[0m  1.2397\n",
            "      4        \u001b[36m0.5484\u001b[0m  1.2562\n",
            "      5        \u001b[36m0.4784\u001b[0m  1.6788\n",
            "      6        0.5731  1.9493\n",
            "      7        \u001b[36m0.4459\u001b[0m  1.2789\n",
            "      8        0.4460  1.2335\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7960\u001b[0m  0.4158\n",
            "      2        1.4422  0.4153\n",
            "      3        \u001b[36m0.7770\u001b[0m  0.4067\n",
            "      4        \u001b[36m0.5478\u001b[0m  0.4453\n",
            "      5        \u001b[36m0.3926\u001b[0m  0.4274\n",
            "      6        1.2178  0.4235\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7883\u001b[0m  0.7949\n",
            "      2        1.2933  0.9063\n",
            "      3        \u001b[36m0.7743\u001b[0m  0.8334\n",
            "      4        \u001b[36m0.7239\u001b[0m  0.7935\n",
            "      5        \u001b[36m0.4674\u001b[0m  0.8431\n",
            "      6        \u001b[36m0.4213\u001b[0m  1.2124\n",
            "      7        0.4404  1.4594\n",
            "      8        \u001b[36m0.3649\u001b[0m  0.8351\n",
            "      9        \u001b[36m0.3443\u001b[0m  0.8857\n",
            "     10        0.3945  0.8397\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9115\u001b[0m  1.1891\n",
            "      2        \u001b[36m0.8241\u001b[0m  1.2363\n",
            "      3        \u001b[36m0.7697\u001b[0m  1.2305\n",
            "      4        0.9028  1.2368\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8198\u001b[0m  0.4005\n",
            "      2        1.1623  0.4443\n",
            "      3        \u001b[36m0.6188\u001b[0m  0.4032\n",
            "      4        \u001b[36m0.4454\u001b[0m  0.4868\n",
            "      5        0.5917  0.4202\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7084\u001b[0m  0.7725\n",
            "      2        1.2689  0.8575\n",
            "      3        \u001b[36m0.5836\u001b[0m  0.8832\n",
            "      4        0.8831  0.8763\n",
            "      5        \u001b[36m0.5160\u001b[0m  0.8984\n",
            "      6        \u001b[36m0.3847\u001b[0m  2.1680\n",
            "      7        0.4409  1.2306\n",
            "      8        \u001b[36m0.3618\u001b[0m  0.9474\n",
            "      9        \u001b[36m0.3349\u001b[0m  0.8200\n",
            "     10        \u001b[36m0.3249\u001b[0m  0.8309\n",
            "     11        0.3857  0.8062\n",
            "     12        \u001b[36m0.3152\u001b[0m  0.8210\n",
            "     13        0.3409  0.8649\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.9429\u001b[0m  1.1694\n",
            "      2        \u001b[36m0.7977\u001b[0m  1.2576\n",
            "      3        \u001b[36m0.7975\u001b[0m  1.6432\n",
            "      4        \u001b[36m0.6652\u001b[0m  1.6506\n",
            "      5        \u001b[36m0.6029\u001b[0m  1.2487\n",
            "      6        \u001b[36m0.5392\u001b[0m  1.2116\n",
            "      7        0.7552  1.1984\n",
            "      8        \u001b[36m0.5205\u001b[0m  1.2427\n",
            "      9        \u001b[36m0.4386\u001b[0m  1.3009\n",
            "     10        0.4705  1.2142\n",
            "     11        \u001b[36m0.4289\u001b[0m  1.2530\n",
            "     12        0.4325  1.3620\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8716\u001b[0m  0.3742\n",
            "      2        \u001b[36m0.8705\u001b[0m  0.4044\n",
            "      3        \u001b[36m0.8697\u001b[0m  0.4099\n",
            "      4        \u001b[36m0.8690\u001b[0m  0.4315\n",
            "      5        \u001b[36m0.8684\u001b[0m  0.4326\n",
            "      6        \u001b[36m0.8680\u001b[0m  0.4497\n",
            "      7        \u001b[36m0.8676\u001b[0m  0.4327\n",
            "      8        \u001b[36m0.8672\u001b[0m  0.4183\n",
            "      9        \u001b[36m0.8669\u001b[0m  0.4029\n",
            "     10        \u001b[36m0.8666\u001b[0m  0.4457\n",
            "     11        \u001b[36m0.8663\u001b[0m  0.4259\n",
            "     12        \u001b[36m0.8661\u001b[0m  0.4250\n",
            "     13        \u001b[36m0.8658\u001b[0m  0.4195\n",
            "     14        \u001b[36m0.8655\u001b[0m  0.4004\n",
            "     15        \u001b[36m0.8653\u001b[0m  0.4338\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8602\u001b[0m  0.7615\n",
            "      2        \u001b[36m0.8600\u001b[0m  1.0223\n",
            "      3        \u001b[36m0.8598\u001b[0m  1.1864\n",
            "      4        \u001b[36m0.8596\u001b[0m  1.0215\n",
            "      5        \u001b[36m0.8594\u001b[0m  0.8054\n",
            "      6        \u001b[36m0.8592\u001b[0m  1.0224\n",
            "      7        \u001b[36m0.8591\u001b[0m  0.7775\n",
            "      8        \u001b[36m0.8589\u001b[0m  0.8229\n",
            "      9        \u001b[36m0.8587\u001b[0m  0.8343\n",
            "     10        \u001b[36m0.8585\u001b[0m  0.8058\n",
            "     11        \u001b[36m0.8583\u001b[0m  0.8345\n",
            "     12        \u001b[36m0.8580\u001b[0m  0.8276\n",
            "     13        \u001b[36m0.8578\u001b[0m  0.8049\n",
            "     14        \u001b[36m0.8575\u001b[0m  0.8356\n",
            "     15        \u001b[36m0.8572\u001b[0m  0.7965\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8542\u001b[0m  1.5063\n",
            "      2        \u001b[36m0.8540\u001b[0m  1.2137\n",
            "      3        \u001b[36m0.8538\u001b[0m  1.2139\n",
            "      4        \u001b[36m0.8537\u001b[0m  1.2272\n",
            "      5        0.8537  1.1954\n",
            "      6        \u001b[36m0.8534\u001b[0m  2.8654\n",
            "      7        \u001b[36m0.8533\u001b[0m  3.1616\n",
            "      8        \u001b[36m0.8530\u001b[0m  1.6717\n",
            "      9        0.8530  1.2028\n",
            "     10        \u001b[36m0.8527\u001b[0m  1.1651\n",
            "     11        \u001b[36m0.8524\u001b[0m  1.2449\n",
            "     12        \u001b[36m0.8522\u001b[0m  1.2385\n",
            "     13        \u001b[36m0.8520\u001b[0m  1.2495\n",
            "     14        \u001b[36m0.8517\u001b[0m  1.1935\n",
            "     15        \u001b[36m0.8514\u001b[0m  1.2211\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8712\u001b[0m  0.5909\n",
            "      2        \u001b[36m0.8702\u001b[0m  0.5978\n",
            "      3        \u001b[36m0.8694\u001b[0m  0.6227\n",
            "      4        \u001b[36m0.8688\u001b[0m  0.5045\n",
            "      5        \u001b[36m0.8684\u001b[0m  0.3919\n",
            "      6        \u001b[36m0.8680\u001b[0m  0.4076\n",
            "      7        \u001b[36m0.8675\u001b[0m  0.4396\n",
            "      8        \u001b[36m0.8673\u001b[0m  0.4286\n",
            "      9        \u001b[36m0.8670\u001b[0m  0.4242\n",
            "     10        \u001b[36m0.8668\u001b[0m  0.4363\n",
            "     11        \u001b[36m0.8666\u001b[0m  0.4647\n",
            "     12        \u001b[36m0.8663\u001b[0m  0.4159\n",
            "     13        \u001b[36m0.8661\u001b[0m  0.3938\n",
            "     14        \u001b[36m0.8659\u001b[0m  0.5728\n",
            "     15        \u001b[36m0.8657\u001b[0m  0.3979\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8603\u001b[0m  0.8120\n",
            "      2        \u001b[36m0.8600\u001b[0m  0.8278\n",
            "      3        \u001b[36m0.8599\u001b[0m  0.8101\n",
            "      4        \u001b[36m0.8597\u001b[0m  0.8345\n",
            "      5        \u001b[36m0.8596\u001b[0m  0.9456\n",
            "      6        \u001b[36m0.8595\u001b[0m  1.1655\n",
            "      7        \u001b[36m0.8594\u001b[0m  1.0908\n",
            "      8        \u001b[36m0.8593\u001b[0m  0.8037\n",
            "      9        \u001b[36m0.8591\u001b[0m  0.8838\n",
            "     10        \u001b[36m0.8590\u001b[0m  0.8203\n",
            "     11        \u001b[36m0.8589\u001b[0m  0.7916\n",
            "     12        \u001b[36m0.8587\u001b[0m  0.7912\n",
            "     13        \u001b[36m0.8586\u001b[0m  0.8385\n",
            "     14        \u001b[36m0.8584\u001b[0m  0.8025\n",
            "     15        \u001b[36m0.8582\u001b[0m  0.9015\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8540\u001b[0m  1.1707\n",
            "      2        \u001b[36m0.8538\u001b[0m  1.4513\n",
            "      3        \u001b[36m0.8536\u001b[0m  1.8640\n",
            "      4        \u001b[36m0.8534\u001b[0m  2.3248\n",
            "      5        \u001b[36m0.8531\u001b[0m  2.2620\n",
            "      6        \u001b[36m0.8531\u001b[0m  3.1244\n",
            "      7        \u001b[36m0.8528\u001b[0m  1.2067\n",
            "      8        \u001b[36m0.8528\u001b[0m  1.3349\n",
            "      9        \u001b[36m0.8526\u001b[0m  1.7516\n",
            "     10        \u001b[36m0.8521\u001b[0m  1.2768\n",
            "     11        \u001b[36m0.8519\u001b[0m  1.2126\n",
            "     12        \u001b[36m0.8516\u001b[0m  1.1836\n",
            "     13        \u001b[36m0.8513\u001b[0m  1.2056\n",
            "     14        \u001b[36m0.8509\u001b[0m  1.2070\n",
            "     15        \u001b[36m0.8505\u001b[0m  1.1694\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8742\u001b[0m  0.3905\n",
            "      2        \u001b[36m0.8683\u001b[0m  0.4639\n",
            "      3        \u001b[36m0.8665\u001b[0m  0.5018\n",
            "      4        \u001b[36m0.8655\u001b[0m  0.5930\n",
            "      5        \u001b[36m0.8641\u001b[0m  0.6059\n",
            "      6        \u001b[36m0.8624\u001b[0m  0.6033\n",
            "      7        \u001b[36m0.8597\u001b[0m  0.6289\n",
            "      8        \u001b[36m0.8551\u001b[0m  0.4303\n",
            "      9        \u001b[36m0.8467\u001b[0m  0.4566\n",
            "     10        \u001b[36m0.8293\u001b[0m  0.3779\n",
            "     11        \u001b[36m0.7873\u001b[0m  0.4147\n",
            "     12        \u001b[36m0.6955\u001b[0m  0.3974\n",
            "     13        0.7267  0.4406\n",
            "     14        \u001b[36m0.5059\u001b[0m  0.4349\n",
            "     15        \u001b[36m0.4130\u001b[0m  0.4418\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8612\u001b[0m  0.7829\n",
            "      2        \u001b[36m0.8591\u001b[0m  0.8262\n",
            "      3        \u001b[36m0.8579\u001b[0m  0.8236\n",
            "      4        \u001b[36m0.8564\u001b[0m  0.8137\n",
            "      5        \u001b[36m0.8538\u001b[0m  0.8996\n",
            "      6        \u001b[36m0.8483\u001b[0m  1.8184\n",
            "      7        \u001b[36m0.8350\u001b[0m  2.0345\n",
            "      8        \u001b[36m0.7904\u001b[0m  0.8749\n",
            "      9        \u001b[36m0.6643\u001b[0m  0.8103\n",
            "     10        \u001b[36m0.6489\u001b[0m  0.8327\n",
            "     11        \u001b[36m0.4756\u001b[0m  0.8073\n",
            "     12        0.5171  0.8381\n",
            "     13        \u001b[36m0.4151\u001b[0m  0.7863\n",
            "     14        0.4956  0.8514\n",
            "     15        \u001b[36m0.3992\u001b[0m  0.7775\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8536\u001b[0m  1.1826\n",
            "      2        \u001b[36m0.8529\u001b[0m  1.2647\n",
            "      3        \u001b[36m0.8523\u001b[0m  1.8540\n",
            "      4        \u001b[36m0.8508\u001b[0m  1.4237\n",
            "      5        \u001b[36m0.8484\u001b[0m  1.2275\n",
            "      6        \u001b[36m0.8409\u001b[0m  1.2490\n",
            "      7        \u001b[36m0.8127\u001b[0m  1.2338\n",
            "      8        \u001b[36m0.6774\u001b[0m  1.1905\n",
            "      9        \u001b[36m0.6062\u001b[0m  1.1933\n",
            "     10        \u001b[36m0.5551\u001b[0m  1.2032\n",
            "     11        0.6211  1.2073\n",
            "     12        \u001b[36m0.5387\u001b[0m  1.6310\n",
            "     13        \u001b[36m0.4560\u001b[0m  1.8880\n",
            "     14        0.5408  1.2552\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8760\u001b[0m  0.3760\n",
            "      2        \u001b[36m0.8685\u001b[0m  0.4742\n",
            "      3        \u001b[36m0.8665\u001b[0m  0.3903\n",
            "      4        \u001b[36m0.8654\u001b[0m  0.4495\n",
            "      5        \u001b[36m0.8641\u001b[0m  0.4362\n",
            "      6        \u001b[36m0.8623\u001b[0m  0.4345\n",
            "      7        \u001b[36m0.8597\u001b[0m  0.4872\n",
            "      8        \u001b[36m0.8557\u001b[0m  0.4161\n",
            "      9        \u001b[36m0.8476\u001b[0m  0.4383\n",
            "     10        \u001b[36m0.8320\u001b[0m  0.4449\n",
            "     11        \u001b[36m0.7962\u001b[0m  0.4486\n",
            "     12        \u001b[36m0.7070\u001b[0m  0.4263\n",
            "     13        \u001b[36m0.5366\u001b[0m  0.6215\n",
            "     14        1.1098  0.5856\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8597\u001b[0m  0.7782\n",
            "      2        \u001b[36m0.8586\u001b[0m  0.8440\n",
            "      3        \u001b[36m0.8571\u001b[0m  0.9017\n",
            "      4        \u001b[36m0.8548\u001b[0m  0.8010\n",
            "      5        \u001b[36m0.8500\u001b[0m  0.8658\n",
            "      6        \u001b[36m0.8380\u001b[0m  0.8291\n",
            "      7        \u001b[36m0.7992\u001b[0m  0.7952\n",
            "      8        \u001b[36m0.6647\u001b[0m  0.8373\n",
            "      9        0.7752  0.7951\n",
            "     10        \u001b[36m0.5211\u001b[0m  0.8532\n",
            "     11        \u001b[36m0.4541\u001b[0m  0.8274\n",
            "     12        \u001b[36m0.4273\u001b[0m  0.9613\n",
            "     13        0.6459  1.1938\n",
            "     14        \u001b[36m0.4057\u001b[0m  1.1011\n",
            "     15        \u001b[36m0.3763\u001b[0m  0.7906\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8540\u001b[0m  1.1599\n",
            "      2        \u001b[36m0.8533\u001b[0m  1.1773\n",
            "      3        \u001b[36m0.8529\u001b[0m  1.2059\n",
            "      4        \u001b[36m0.8505\u001b[0m  1.1932\n",
            "      5        \u001b[36m0.8473\u001b[0m  1.2102\n",
            "      6        \u001b[36m0.8359\u001b[0m  1.1738\n",
            "      7        \u001b[36m0.7923\u001b[0m  1.6143\n",
            "      8        \u001b[36m0.6991\u001b[0m  1.6431\n",
            "      9        0.7138  1.3525\n",
            "     10        \u001b[36m0.6256\u001b[0m  1.1800\n",
            "     11        \u001b[36m0.5633\u001b[0m  1.2680\n",
            "     12        \u001b[36m0.5151\u001b[0m  1.2915\n",
            "     13        0.6730  1.1911\n",
            "     14        \u001b[36m0.4758\u001b[0m  1.1950\n",
            "     15        \u001b[36m0.4684\u001b[0m  1.1933\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8700\u001b[0m  0.5926\n",
            "      2        \u001b[36m0.8658\u001b[0m  0.6128\n",
            "      3        \u001b[36m0.8632\u001b[0m  0.4492\n",
            "      4        \u001b[36m0.8573\u001b[0m  0.4533\n",
            "      5        \u001b[36m0.8407\u001b[0m  0.4511\n",
            "      6        \u001b[36m0.7673\u001b[0m  0.3984\n",
            "      7        0.9937  0.3877\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8593\u001b[0m  0.7654\n",
            "      2        \u001b[36m0.8565\u001b[0m  0.8172\n",
            "      3        \u001b[36m0.8459\u001b[0m  0.8540\n",
            "      4        \u001b[36m0.7749\u001b[0m  0.8100\n",
            "      5        0.8501  0.8329\n",
            "      6        \u001b[36m0.5773\u001b[0m  0.7734\n",
            "      7        0.7951  0.7750\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8536\u001b[0m  1.4085\n",
            "      2        \u001b[36m0.8520\u001b[0m  1.1901\n",
            "      3        \u001b[36m0.8475\u001b[0m  1.1988\n",
            "      4        \u001b[36m0.7988\u001b[0m  1.2214\n",
            "      5        \u001b[36m0.7739\u001b[0m  1.1598\n",
            "      6        \u001b[36m0.6966\u001b[0m  1.1845\n",
            "      7        \u001b[36m0.5655\u001b[0m  1.2097\n",
            "      8        0.6588  1.2130\n",
            "      9        \u001b[36m0.5536\u001b[0m  1.6186\n",
            "     10        \u001b[36m0.5188\u001b[0m  1.7362\n",
            "     11        0.8964  1.1757\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8742\u001b[0m  0.3920\n",
            "      2        \u001b[36m0.8670\u001b[0m  0.4305\n",
            "      3        \u001b[36m0.8655\u001b[0m  0.3785\n",
            "      4        \u001b[36m0.8631\u001b[0m  0.4305\n",
            "      5        \u001b[36m0.8577\u001b[0m  0.4345\n",
            "      6        \u001b[36m0.8430\u001b[0m  0.4449\n",
            "      7        \u001b[36m0.7837\u001b[0m  0.4226\n",
            "      8        0.8213  0.4252\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8600\u001b[0m  0.7646\n",
            "      2        \u001b[36m0.8587\u001b[0m  1.1760\n",
            "      3        \u001b[36m0.8564\u001b[0m  1.2141\n",
            "      4        \u001b[36m0.8491\u001b[0m  0.9248\n",
            "      5        \u001b[36m0.8051\u001b[0m  0.8263\n",
            "      6        \u001b[36m0.7142\u001b[0m  0.8222\n",
            "      7        0.8331  0.8325\n",
            "      8        \u001b[36m0.6867\u001b[0m  0.8777\n",
            "      9        \u001b[36m0.6502\u001b[0m  0.8047\n",
            "     10        \u001b[36m0.6419\u001b[0m  0.8376\n",
            "     11        \u001b[36m0.5796\u001b[0m  0.8189\n",
            "     12        \u001b[36m0.5001\u001b[0m  0.8179\n",
            "     13        0.5260  0.8252\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8527\u001b[0m  1.8505\n",
            "      2        0.8578  1.2751\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 3\n",
            "n_resources: 76548\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8685\u001b[0m  1.6557\n",
            "      2        \u001b[36m0.8611\u001b[0m  1.5787\n",
            "      3        \u001b[36m0.8191\u001b[0m  1.6326\n",
            "      4        \u001b[36m0.6009\u001b[0m  2.0287\n",
            "      5        \u001b[36m0.4677\u001b[0m  2.0219\n",
            "      6        \u001b[36m0.3308\u001b[0m  1.6184\n",
            "      7        \u001b[36m0.3091\u001b[0m  1.5994\n",
            "      8        \u001b[36m0.2953\u001b[0m  1.5630\n",
            "      9        \u001b[36m0.2914\u001b[0m  1.5686\n",
            "     10        \u001b[36m0.2628\u001b[0m  1.5843\n",
            "     11        0.2649  1.6917\n",
            "     12        \u001b[36m0.2541\u001b[0m  2.3122\n",
            "     13        \u001b[36m0.2431\u001b[0m  1.5697\n",
            "     14        0.2557  1.6266\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8603\u001b[0m  4.0647\n",
            "      2        \u001b[36m0.8401\u001b[0m  3.1069\n",
            "      3        \u001b[36m0.7313\u001b[0m  3.3620\n",
            "      4        \u001b[36m0.4818\u001b[0m  3.1221\n",
            "      5        \u001b[36m0.4588\u001b[0m  4.0042\n",
            "      6        \u001b[36m0.4030\u001b[0m  3.2096\n",
            "      7        \u001b[36m0.3737\u001b[0m  3.1107\n",
            "      8        \u001b[36m0.3545\u001b[0m  3.4529\n",
            "      9        \u001b[36m0.3309\u001b[0m  3.6465\n",
            "     10        \u001b[36m0.3186\u001b[0m  3.2049\n",
            "     11        0.3299  3.1505\n",
            "     12        \u001b[36m0.3068\u001b[0m  3.9817\n",
            "     13        0.3125  3.1176\n",
            "     14        \u001b[36m0.2847\u001b[0m  3.0601\n",
            "     15        0.2980  3.0799\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.8524\u001b[0m  4.5876\n",
            "      2        \u001b[36m0.7203\u001b[0m  5.5296\n",
            "      3        \u001b[36m0.5468\u001b[0m  4.6397\n",
            "      4        \u001b[36m0.4477\u001b[0m  4.6564\n",
            "      5        \u001b[36m0.4090\u001b[0m  5.7063\n",
            "      6        \u001b[36m0.3994\u001b[0m  4.6426\n",
            "      7        \u001b[36m0.3874\u001b[0m  5.6038\n",
            "      8        \u001b[36m0.3787\u001b[0m  4.7017\n",
            "      9        \u001b[36m0.3704\u001b[0m  4.8112\n",
            "     10        \u001b[36m0.3622\u001b[0m  5.4351\n",
            "     11        \u001b[36m0.3550\u001b[0m  4.6690\n",
            "     12        \u001b[36m0.3474\u001b[0m  5.5390\n",
            "     13        0.3601  4.7033\n",
            "     14        \u001b[36m0.3432\u001b[0m  4.9095\n",
            "     15        0.3474  5.3304\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6388\u001b[0m  2.4375\n",
            "      2        0.6433  1.6212\n",
            "      3        \u001b[36m0.3206\u001b[0m  1.6132\n",
            "      4        \u001b[36m0.2951\u001b[0m  1.6264\n",
            "      5        \u001b[36m0.2899\u001b[0m  1.6778\n",
            "      6        \u001b[36m0.2586\u001b[0m  1.7072\n",
            "      7        0.2767  1.7868\n",
            "      8        \u001b[36m0.2464\u001b[0m  2.4444\n",
            "      9        0.2491  1.6836\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6422\u001b[0m  3.1752\n",
            "      2        \u001b[36m0.4161\u001b[0m  3.9860\n",
            "      3        \u001b[36m0.3717\u001b[0m  3.1551\n",
            "      4        \u001b[36m0.3528\u001b[0m  3.1219\n",
            "      5        \u001b[36m0.3402\u001b[0m  3.6596\n",
            "      6        \u001b[36m0.3246\u001b[0m  3.5232\n",
            "      7        \u001b[36m0.3186\u001b[0m  3.1820\n",
            "      8        \u001b[36m0.3149\u001b[0m  3.2401\n",
            "      9        \u001b[36m0.2971\u001b[0m  4.3317\n",
            "     10        0.2972  3.2471\n",
            "     11        \u001b[36m0.2955\u001b[0m  3.2228\n",
            "     12        \u001b[36m0.2893\u001b[0m  3.3307\n",
            "     13        \u001b[36m0.2856\u001b[0m  3.8163\n",
            "     14        \u001b[36m0.2814\u001b[0m  3.1761\n",
            "     15        \u001b[36m0.2719\u001b[0m  3.1624\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6544\u001b[0m  4.8056\n",
            "      2        \u001b[36m0.4674\u001b[0m  5.5551\n",
            "      3        \u001b[36m0.4219\u001b[0m  4.8015\n",
            "      4        \u001b[36m0.4056\u001b[0m  4.8050\n",
            "      5        \u001b[36m0.3825\u001b[0m  5.6120\n",
            "      6        0.3878  4.7187\n",
            "      7        \u001b[36m0.3697\u001b[0m  5.6571\n",
            "      8        \u001b[36m0.3558\u001b[0m  4.7321\n",
            "      9        0.3583  4.8014\n",
            "     10        \u001b[36m0.3512\u001b[0m  5.6294\n",
            "     11        \u001b[36m0.3428\u001b[0m  5.0061\n",
            "     12        0.3440  5.6364\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7471\u001b[0m  1.5731\n",
            "      2        \u001b[36m0.3875\u001b[0m  1.6755\n",
            "      3        \u001b[36m0.3593\u001b[0m  1.6213\n",
            "      4        \u001b[36m0.2923\u001b[0m  1.6800\n",
            "      5        0.3061  1.6648\n",
            "      6        \u001b[36m0.2663\u001b[0m  2.0784\n",
            "      7        0.2739  2.0744\n",
            "      8        \u001b[36m0.2469\u001b[0m  1.5997\n",
            "      9        \u001b[36m0.2428\u001b[0m  1.6510\n",
            "     10        0.2695  1.6405\n",
            "     11        \u001b[36m0.2317\u001b[0m  1.7395\n",
            "     12        0.2460  1.6303\n",
            "     13        \u001b[36m0.2311\u001b[0m  1.9417\n",
            "     14        \u001b[36m0.2271\u001b[0m  2.1166\n",
            "     15        \u001b[36m0.2225\u001b[0m  1.6402\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.7312\u001b[0m  3.2428\n",
            "      2        \u001b[36m0.4210\u001b[0m  4.0891\n",
            "      3        \u001b[36m0.3655\u001b[0m  3.2612\n",
            "      4        \u001b[36m0.3599\u001b[0m  3.2948\n",
            "      5        \u001b[36m0.3331\u001b[0m  3.5219\n",
            "      6        \u001b[36m0.3232\u001b[0m  3.6899\n",
            "      7        \u001b[36m0.3216\u001b[0m  3.2003\n",
            "      8        \u001b[36m0.3132\u001b[0m  3.3108\n",
            "      9        \u001b[36m0.2924\u001b[0m  4.0664\n",
            "     10        0.3101  3.2315\n",
            "Stopping since train_loss has not improved in the last 2 epochs.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6450\u001b[0m  4.6850\n",
            "      2        \u001b[36m0.4769\u001b[0m  4.6578\n",
            "      3        \u001b[36m0.4237\u001b[0m  5.5693\n",
            "      4        \u001b[36m0.4120\u001b[0m  4.7392\n",
            "      5        \u001b[36m0.3956\u001b[0m  5.5722\n",
            "      6        \u001b[36m0.3745\u001b[0m  4.9848\n",
            "      7        \u001b[36m0.3697\u001b[0m  4.9987\n",
            "      8        \u001b[36m0.3666\u001b[0m  5.3358\n",
            "      9        \u001b[36m0.3589\u001b[0m  4.7142\n",
            "     10        \u001b[36m0.3520\u001b[0m  5.5616\n",
            "     11        0.3586  4.7308\n",
            "     12        \u001b[36m0.3477\u001b[0m  5.3094\n",
            "     13        \u001b[36m0.3416\u001b[0m  5.1090\n",
            "     14        0.3431  4.7271\n",
            "     15        \u001b[36m0.3405\u001b[0m  5.6311\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6100\u001b[0m  8.7745\n",
            "      2        \u001b[36m0.4661\u001b[0m  8.9194\n",
            "      3        \u001b[36m0.4400\u001b[0m  7.8124\n",
            "      4        \u001b[36m0.4199\u001b[0m  8.7167\n",
            "      5        \u001b[36m0.4089\u001b[0m  8.7258\n",
            "      6        \u001b[36m0.4036\u001b[0m  7.8717\n",
            "      7        \u001b[36m0.3917\u001b[0m  8.7768\n",
            "      8        \u001b[36m0.3883\u001b[0m  8.9212\n",
            "      9        \u001b[36m0.3803\u001b[0m  8.2070\n",
            "     10        \u001b[36m0.3725\u001b[0m  8.3219\n",
            "     11        0.3755  8.7815\n",
            "     12        \u001b[36m0.3673\u001b[0m  8.2681\n",
            "     13        0.3691  8.2328\n",
            "     14        \u001b[36m0.3609\u001b[0m  8.7671\n",
            "     15        0.3615  8.7987\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.6419\u001b[0m  5.9228\n",
            "      2        \u001b[36m0.4524\u001b[0m  6.7024\n",
            "      3        \u001b[36m0.4098\u001b[0m  5.8751\n",
            "      4        \u001b[36m0.3937\u001b[0m  6.7922\n",
            "      5        \u001b[36m0.3780\u001b[0m  5.8872\n",
            "      6        \u001b[36m0.3654\u001b[0m  6.7596\n",
            "      7        \u001b[36m0.3599\u001b[0m  5.9007\n",
            "      8        \u001b[36m0.3506\u001b[0m  7.0227\n",
            "      9        \u001b[36m0.3451\u001b[0m  6.0356\n",
            "     10        0.3458  6.7850\n",
            "     11        \u001b[36m0.3382\u001b[0m  5.9610\n",
            "     12        \u001b[36m0.3372\u001b[0m  6.6708\n",
            "     13        \u001b[36m0.3292\u001b[0m  5.9073\n",
            "     14        \u001b[36m0.3290\u001b[0m  6.8077\n",
            "     15        \u001b[36m0.3238\u001b[0m  5.8418\n",
            "τ* (last-fold, max F1): 0.4045\n",
            "\n",
            "=== MLP (skorch, SGD) — Halving v2 ===\n",
            "best params: {'clf__batch_size': 2048, 'clf__module__hidden': (1024, 128), 'clf__optimizer__lr': 0.5, 'clf__optimizer__weight_decay': 0.0001}\n",
            "param count: 215297 | epochs: 15\n",
            "best CV ROC-AUC: 0.8466\n",
            "train ROC-AUC: 0.9508\n",
            "test  ROC-AUC: 0.8488\n",
            "train acc @τ*: 0.8739\n",
            "test  acc @τ*: 0.771\n",
            "train AP: 0.9326\n",
            "test  AP: 0.7441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=[1024, 128], out_dim=1, dropout_p=0.0):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        dims = [in_dim] + hidden\n",
        "        for i in range(len(dims)-1):\n",
        "            layers += [nn.Linear(dims[i], dims[i+1]), nn.ReLU()]\n",
        "            if dropout_p > 0: layers += [nn.Dropout(p=dropout_p)]\n",
        "        layers += [nn.Linear(hidden[-1] if hidden else in_dim, out_dim)]  # out_dim=1 for binary\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1)  # logits; don’t add Sigmoid here\n"
      ],
      "metadata": {
        "id": "dEXl1_BQIs2n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_layers(model):\n",
        "    return [m for m in model.modules() if isinstance(m, nn.Linear)]\n",
        "\n",
        "def freeze_all_but_last_k(model, k=2):\n",
        "    layers = linear_layers(model)\n",
        "    # Freeze all first:\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "    # Unfreeze last k Linear layers:\n",
        "    for m in layers[-k:]:\n",
        "        for p in m.parameters():\n",
        "            p.requires_grad = True\n",
        "    # Report counts (needed for RO cap)\n",
        "    tot = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Params total={tot:,} | trainable(last {k})={trainable:,}\")\n",
        "    return trainable\n",
        "\n",
        "# Example: freeze all but last 1–3 layers for Part 1 RO\n",
        "model = MLP(in_dim=Xtr_t.shape[1], hidden=[1024, 128], out_dim=1).to(device)\n",
        "trainable = freeze_all_but_last_k(model, k=1)\n",
        "assert trainable <= 50_000, \"RO parameter cap exceeded.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-VOP_qNlk2",
        "outputId": "514c6cc7-48b2-4977-8552-a48373c6803e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params total=215,297 | trainable(last 1)=129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"classification\"  # or \"regression\"\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n"
      ],
      "metadata": {
        "id": "PS0LkF73OXB8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve,\n",
        "    average_precision_score, precision_recall_curve,\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "# --- Fit isotonic calibrator on VALIDATION (once) ---\n",
        "model.eval()\n",
        "val_logits, val_y = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        val_logits.append(model(xb).cpu().numpy())\n",
        "        val_y.append(yb.cpu().numpy())\n",
        "import numpy as np\n",
        "val_logits = np.concatenate(val_logits)\n",
        "val_y      = np.concatenate(val_y).astype(int)\n",
        "\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "def sigmoid_np(x):  # keep your helper available early\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "val_p = sigmoid_np(val_logits)                   # probs from logits\n",
        "iso   = IsotonicRegression(out_of_bounds=\"clip\")\n",
        "iso.fit(val_p, val_y)                            # <-- trains the calibrator\n",
        "\n",
        "def calibrate_probs_isotonic(p):                 # p are uncalibrated probs\n",
        "    return iso.transform(p)\n",
        "\n",
        "def sigmoid_np(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def pick_threshold_max_f1(y_true, scores):\n",
        "    P, R, T = precision_recall_curve(y_true, scores)  # len(T) = len(P)-1\n",
        "    f1 = 2 * P[1:] * R[1:] / (P[1:] + R[1:] + 1e-12)\n",
        "    i = int(np.nanargmax(f1))\n",
        "    return float(T[i]), float(f1[i]), float(P[i+1]), float(R[i+1])\n",
        "\n",
        "def eval_on_loader(model, loader, threshold=None, pick_rule=\"max_f1\"):\n",
        "    \"\"\"\n",
        "    model: returns logits (no sigmoid).\n",
        "    loader: DataLoader yielding (X, y) with y in {0,1}.\n",
        "    threshold:\n",
        "        - None + pick_rule=\"max_f1\" -> choose t that maximizes F1 on these scores.\n",
        "        - float in [0,1] -> use exactly this probability cutoff.\n",
        "    Returns: dict of metrics + curves + chosen threshold.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    logits, ys = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            logits.append(model(xb).cpu().numpy())\n",
        "            ys.append(yb.cpu().numpy())\n",
        "    logits = np.concatenate(logits).astype(np.float64)\n",
        "    y = np.concatenate(ys).astype(np.int32)\n",
        "\n",
        "    # Probabilities for metrics that need them\n",
        "    p = sigmoid_np(logits)\n",
        "    p = calibrate_probs_isotonic(p)\n",
        "\n",
        "    # Curves + areas (threshold-free summaries)\n",
        "    auroc = roc_auc_score(y, logits)                 # OK to use logits\n",
        "    fpr, tpr, roc_th = roc_curve(y, logits)\n",
        "    aupr  = average_precision_score(y, p)            # area under PR; aka AUC-PR\n",
        "    prec_curve, rec_curve, pr_th = precision_recall_curve(y, p)\n",
        "\n",
        "    # Pick threshold if not given\n",
        "    if threshold is None:\n",
        "        if pick_rule == \"max_f1\":\n",
        "            t_star, _, _, _ = pick_threshold_max_f1(y, p)\n",
        "        elif pick_rule == \"fixed_0p5\":\n",
        "            t_star = 0.5\n",
        "        elif pick_rule == \"match_prevalence\":\n",
        "            # choose t so predicted positive rate roughly matches prevalence\n",
        "            prev = y.mean()\n",
        "            # find t where mean(p >= t) is closest to prev\n",
        "            cand = np.linspace(0.0, 1.0, 1001)\n",
        "            idx = np.argmin(np.abs((p[:,None] >= cand).mean(axis=0) - prev))\n",
        "            t_star = float(cand[idx])\n",
        "        else:\n",
        "            t_star = 0.5\n",
        "    else:\n",
        "        t_star = float(threshold)\n",
        "\n",
        "    yhat = (p >= t_star).astype(int)\n",
        "\n",
        "    # At-threshold metrics (“calibrated”)\n",
        "    acc  = accuracy_score(y, yhat)\n",
        "    prec = precision_score(y, yhat, zero_division=0)\n",
        "    rec  = recall_score(y, yhat, zero_division=0)\n",
        "    f1   = f1_score(y, yhat, zero_division=0)\n",
        "    prev = float(y.mean())\n",
        "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
        "\n",
        "    return {\n",
        "        \"threshold\": t_star,\n",
        "        # single-number summaries from curves:\n",
        "        \"auroc\": float(auroc),          # area under ROC curve\n",
        "        \"aupr\": float(aupr),            # area under Precision-Recall (AUC-PR)\n",
        "        # at-threshold (“calibrated”) scores:\n",
        "        \"accuracy\": float(acc),\n",
        "        \"precision\": float(prec),\n",
        "        \"recall\": float(rec),\n",
        "        \"f1\": float(f1),\n",
        "        \"prevalence\": prev,\n",
        "        \"confusion\": {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)},\n",
        "        # full curves if you want to plot later:\n",
        "        \"roc_curve\": {\"fpr\": fpr, \"tpr\": tpr, \"thr\": roc_th},\n",
        "        \"pr_curve\":  {\"precision\": prec_curve, \"recall\": rec_curve, \"thr\": pr_th},\n",
        "    }\n"
      ],
      "metadata": {
        "id": "fymIoiByO-GD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: choose threshold that maximizes F1 on the validation split\n",
        "val_metrics = eval_on_loader(model, val_loader, threshold=None, pick_rule=\"max_f1\")\n",
        "print(val_metrics[\"threshold\"], val_metrics[\"auroc\"], val_metrics[\"aupr\"],\n",
        "      val_metrics[\"precision\"], val_metrics[\"recall\"], val_metrics[\"f1\"])\n",
        "t_star = val_metrics[\"threshold\"]\n",
        "test_metrics = eval_on_loader(model, test_loader, threshold=t_star)\n",
        "def pretty_print_metrics(name, M):\n",
        "    C = M[\"confusion\"]\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Threshold (picked): {M['threshold']:.3f}\")\n",
        "    print(f\"AUROC: {M['auroc']:.3f}  |  AUPR: {M['aupr']:.3f}  |  Prevalence: {M['prevalence']:.3f}\")\n",
        "    print(f\"Accuracy:  {M.get('accuracy', float('nan')):.3f}\")\n",
        "    print(f\"Precision: {M['precision']:.3f}  |  Recall: {M['recall']:.3f}  |  F1: {M['f1']:.3f}\")\n",
        "    print(f\"Confusion @ threshold → TN:{C['tn']}  FP:{C['fp']}  FN:{C['fn']}  TP:{C['tp']}\")\n",
        "\n",
        "# usage\n",
        "pretty_print_metrics(\"Validation\", val_metrics)\n",
        "pretty_print_metrics(\"Test\", test_metrics)\n"
      ],
      "metadata": {
        "id": "L51R2d4ZqJXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbca7f1-333d-41d1-fcad-d676208c7623"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30392053723335266 0.8004759466963438 0.7486948639676017 0.568222982491447 0.779649316581527 0.6573540538967464\n",
            "\n",
            "=== Validation ===\n",
            "Threshold (picked): 0.304\n",
            "AUROC: 0.800  |  AUPR: 0.749  |  Prevalence: 0.379\n",
            "Accuracy:  0.692\n",
            "Precision: 0.568  |  Recall: 0.780  |  F1: 0.657\n",
            "Confusion @ threshold → TN:7574  FP:4291  FN:1596  TP:5647\n",
            "\n",
            "=== Test ===\n",
            "Threshold (picked): 0.304\n",
            "AUROC: 0.756  |  AUPR: 0.595  |  Prevalence: 0.315\n",
            "Accuracy:  0.617\n",
            "Precision: 0.441  |  Recall: 0.814  |  F1: 0.572\n",
            "Confusion @ threshold → TN:8550  FP:7688  FN:1391  TP:6074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np\n",
        "from torch import nn\n",
        "\n",
        "def get_last_k_linear_layers(model: nn.Module, k: int):\n",
        "    layers = [m for m in model.modules() if isinstance(m, nn.Linear)]\n",
        "    return layers[-k:] if k > 0 else []\n",
        "\n",
        "@torch.no_grad()\n",
        "def tail_to_vector(model: nn.Module, k: int) -> torch.Tensor:\n",
        "    \"\"\"Flatten last-k Linear layers' (weight, bias) into one 1-D tensor on CPU.\"\"\"\n",
        "    vecs = []\n",
        "    for layer in get_last_k_linear_layers(model, k):\n",
        "        vecs += [layer.weight.detach().flatten().cpu()]\n",
        "        if layer.bias is not None:\n",
        "            vecs += [layer.bias.detach().flatten().cpu()]\n",
        "    return torch.cat(vecs) if vecs else torch.empty(0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def vector_to_tail(model: nn.Module, k: int, vec: torch.Tensor, device=None):\n",
        "    \"\"\"Write a flat vector back into the last-k Linear layers in order.\"\"\"\n",
        "    if device is None: device = next(model.parameters()).device\n",
        "    idx = 0\n",
        "    for layer in get_last_k_linear_layers(model, k):\n",
        "        W = layer.weight\n",
        "        nW = W.numel()\n",
        "        W.copy_(vec[idx:idx+nW].view_as(W).to(device))\n",
        "        idx += nW\n",
        "        if layer.bias is not None:\n",
        "            b = layer.bias\n",
        "            nb = b.numel()\n",
        "            b.copy_(vec[idx:idx+nb].view_as(b).to(device))\n",
        "            idx += nb\n",
        "    assert idx == vec.numel(), \"Vector length mismatch when restoring tail params.\"\n"
      ],
      "metadata": {
        "id": "rzP6DjHV4ISu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "def run_epoch(model, loader, optimizer=None):\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "    total_loss, n, grad_evals = 0.0, 0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        if is_train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            if is_train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                grad_evals += 1  # count one optimizer step = one gradient evaluation\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        n += xb.size(0)\n",
        "    return total_loss / n, grad_evals\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total, n_batches = 0.0, 0\n",
        "    for xb, yb in loader:\n",
        "        total += criterion(model(xb.to(device)), yb.to(device)).item()\n",
        "        n_batches += 1\n",
        "    return total / n_batches"
      ],
      "metadata": {
        "id": "mbkLdtvTTi-7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# objective wrapper that takes a candidate param vector\n",
        "@torch.no_grad()\n",
        "def objective_from_vec(model, k, vec, val_loader):\n",
        "    vector_to_tail(model, k, vec)\n",
        "    return evaluate(model, val_loader)  # returns mean val loss (scalar float)\n"
      ],
      "metadata": {
        "id": "ceF_BqKGS3cU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rhc(model, k, val_loader, start_vec=None, sigma=0.01, restarts=3, budget=2000, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    best_vec = start_vec.clone() if start_vec is not None else tail_to_vector(model, k)\n",
        "    best_loss = objective_from_vec(model, k, best_vec, val_loader)\n",
        "    evals = 1\n",
        "    history = [(evals, best_loss)]\n",
        "\n",
        "    for r in range(restarts+1):\n",
        "        cur_vec = best_vec.clone()\n",
        "        cur_loss = best_loss\n",
        "        while evals < budget:\n",
        "            step = torch.from_numpy(rng.normal(0.0, sigma, size=cur_vec.numel()).astype(np.float32))\n",
        "            cand = cur_vec + step\n",
        "            loss = objective_from_vec(model, k, cand, val_loader)\n",
        "            evals += 1\n",
        "            if loss < cur_loss:\n",
        "                cur_vec, cur_loss = cand, loss\n",
        "                if loss < best_loss:\n",
        "                    best_vec, best_loss = cand.clone(), loss\n",
        "            history.append((evals, best_loss))\n",
        "        # simple restart: randomize around global best\n",
        "        if r < restarts:\n",
        "            cur_vec = best_vec + torch.from_numpy(rng.normal(0.0, sigma*2, size=best_vec.numel()).astype(np.float32))\n",
        "            cur_loss = objective_from_vec(model, k, cur_vec, val_loader); evals += 1\n",
        "            history.append((evals, min(best_loss, cur_loss)))\n",
        "    # restore best\n",
        "    vector_to_tail(model, k, best_vec)\n",
        "    return {\"best_loss\": best_loss, \"best_vec\": best_vec, \"history\": history, \"evals\": evals}\n"
      ],
      "metadata": {
        "id": "oj16vSiqS3lc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sa(model, k, val_loader, start_vec=None, sigma=0.01, T0=1.0, decay=0.995, budget=2000, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    cur = start_vec.clone() if start_vec is not None else tail_to_vector(model, k)\n",
        "    cur_loss = objective_from_vec(model, k, cur, val_loader)\n",
        "    best, best_loss = cur.clone(), cur_loss\n",
        "    T, evals = T0, 1\n",
        "    history = [(evals, best_loss)]\n",
        "\n",
        "    while evals < budget:\n",
        "        step = torch.from_numpy(rng.normal(0.0, sigma, size=cur.numel()).astype(np.float32))\n",
        "        cand = cur + step\n",
        "        loss = objective_from_vec(model, k, cand, val_loader); evals += 1\n",
        "        d = loss - cur_loss\n",
        "        # accept if better or with probability exp(-d/T)\n",
        "        if d < 0 or rng.random() < np.exp(-d / max(T, 1e-8)):\n",
        "            cur, cur_loss = cand, loss\n",
        "            if loss < best_loss:\n",
        "                best, best_loss = cand.clone(), loss\n",
        "        history.append((evals, best_loss))\n",
        "        T *= decay  # cool down\n",
        "    vector_to_tail(model, k, best)\n",
        "    return {\"best_loss\": best_loss, \"best_vec\": best, \"history\": history, \"evals\": evals}\n"
      ],
      "metadata": {
        "id": "BczMVUEhS3vr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ga(model, k, val_loader, pop_size=32, elite_frac=0.1, mut_rate=0.1, sigma=0.01,\n",
        "       generations=200, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    base = tail_to_vector(model, k).numpy().astype(np.float32)\n",
        "    dim = base.size\n",
        "    elite_k = max(1, int(pop_size * elite_frac))\n",
        "    budget = 0\n",
        "    # init population around base\n",
        "    pop = base[None, :] + rng.normal(0, sigma, size=(pop_size, dim)).astype(np.float32)\n",
        "\n",
        "    def fitness(vec):\n",
        "        nonlocal budget\n",
        "        vec_t = torch.from_numpy(vec)\n",
        "        loss = objective_from_vec(model, k, vec_t, val_loader)\n",
        "        budget += 1\n",
        "        return loss\n",
        "\n",
        "    losses = np.array([fitness(v) for v in pop])\n",
        "    history = [(budget, float(losses.min()))]\n",
        "    best = pop[losses.argmin()].copy()\n",
        "\n",
        "    for _ in range(generations):\n",
        "        # select by rank (lower loss is better)\n",
        "        idx = np.argsort(losses)\n",
        "        elites = pop[idx[:elite_k]]\n",
        "        # tournament for parents\n",
        "        parents = pop[idx[:pop_size//2]]\n",
        "\n",
        "        # crossover (uniform)\n",
        "        children = []\n",
        "        while len(children) < pop_size - elite_k:\n",
        "            a, b = parents[rng.integers(0, parents.shape[0])], parents[rng.integers(0, parents.shape[0])]\n",
        "            mask = rng.random(dim) < 0.5\n",
        "            child = np.where(mask, a, b).astype(np.float32)\n",
        "            # mutation\n",
        "            mut_mask = rng.random(dim) < mut_rate\n",
        "            child[mut_mask] += rng.normal(0, sigma, size=mut_mask.sum()).astype(np.float32)\n",
        "            children.append(child)\n",
        "        pop = np.vstack([elites, np.stack(children, axis=0)])\n",
        "\n",
        "        losses = np.array([fitness(v) for v in pop])\n",
        "        if losses.min() < objective_from_vec(model, k, torch.from_numpy(best), val_loader):\n",
        "            best = pop[losses.argmin()].copy()\n",
        "        history.append((budget, float(losses.min())))\n",
        "\n",
        "    vector_to_tail(model, k, torch.from_numpy(best))\n",
        "    return {\"best_loss\": float(objective_from_vec(model, k, torch.from_numpy(best), val_loader)),\n",
        "            \"best_vec\": torch.from_numpy(best), \"history\": history, \"evals\": budget}\n"
      ],
      "metadata": {
        "id": "AVSQGPQtTCaU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = evaluate(model, val_loader)\n",
        "print(\"baseline val loss:\", baseline)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SisxjNWTcUO-",
        "outputId": "e370f481-fa57-462f-cd8d-f618158d1583"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "baseline val loss: 0.5985719310609918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(val_loader))\n",
        "logits = model(xb.to(device))        # expect shape [N]  (not [N,1])\n",
        "print(\"logits shape:\", tuple(logits.shape), \"yb shape:\", tuple(yb.shape))\n",
        "\n",
        "# If logits is [N,1], either:\n",
        "#   (a) return logits.squeeze(-1) in forward(), or\n",
        "#   (b) use yb = yb.unsqueeze(1).float() in the loss call.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTiSxX7UdV8t",
        "outputId": "b15bfca8-2d30-49bb-ae0e-1966c91725fb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (1024,) yb shape: (1024,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "ybf = yb.to(device).float()\n",
        "l_mean = F.binary_cross_entropy_with_logits(logits, ybf, reduction='mean')\n",
        "l_sum  = F.binary_cross_entropy_with_logits(logits, ybf, reduction='sum')\n",
        "print(\"one-batch BCE mean:\", float(l_mean), \" sum:\", float(l_sum))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siEdGY41djmj",
        "outputId": "36e9d3ef-17fd-4a7f-a976-1a4b2bfb0c43"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one-batch BCE mean: 0.58781898021698  sum: 601.9266357421875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(criterion), getattr(criterion, \"reduction\", None))\n",
        "# Should be: <class 'torch.nn.modules.loss.BCEWithLogitsLoss'>  'mean'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMT-px3WdQsc",
        "outputId": "c474d07e-431e-4f51-c344-8c57a9b6a997"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.loss.BCEWithLogitsLoss'> mean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure: model has all but last k layers frozen, criterion is BCEWithLogitsLoss,\n",
        "# val_loader is fixed, model.eval() is used inside evaluate() (it is).\n",
        "\n",
        "k = 1 # how many frozen layers there are\n",
        "start_vec = tail_to_vector(model, k)  # warm start from your trained checkpoint\n",
        "\n",
        "# RHC\n",
        "rhc_res = rhc(model, k, val_loader, start_vec=start_vec, sigma=0.01, restarts=2, budget=2000, seed=42)\n",
        "print(\"RHC best val loss:\", rhc_res[\"best_loss\"])\n",
        "\n",
        "# SA\n",
        "sa_res  = sa(model, k, val_loader, start_vec=start_vec, sigma=0.01, T0=1.0, decay=0.997, budget=2000, seed=42)\n",
        "print(\"SA best val loss:\", sa_res[\"best_loss\"])\n",
        "\n",
        "# GA\n",
        "ga_res  = ga(model, k, val_loader, pop_size=32, elite_frac=0.125, mut_rate=0.05, sigma=0.02,\n",
        "             generations=100, seed=42)\n",
        "print(\"GA best val loss:\", ga_res[\"best_loss\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpKkMWyGTCy7",
        "outputId": "ddc8cd1f-06d2-4980-a804-278b5cf112dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RHC best val loss: 0.48589848060356944\n",
            "SA best val loss: 0.58419941914709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_and_save_ro_progress(rhc_res, sa_res, ga_res,\n",
        "                              title=\"Part 1: RO progress (val loss vs evals)\",\n",
        "                              png_path=\"ro_progress.png\",\n",
        "                              pdf_path=\"ro_progress.pdf\"):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    for name, res in [(\"RHC\", rhc_res), (\"SA\", sa_res), (\"GA\", ga_res)]:\n",
        "        if \"history\" not in res or not res[\"history\"]:\n",
        "            continue\n",
        "        xs = [e for e, _ in res[\"history\"]]\n",
        "        ys = [b for _, b in res[\"history\"]]\n",
        "        plt.plot(xs, ys, label=name)\n",
        "    plt.xlabel(\"Function evaluations (validation-loss calls)\")\n",
        "    plt.ylabel(\"Best-so-far validation loss\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    # save first, then show\n",
        "    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {png_path} and {pdf_path}\")\n"
      ],
      "metadata": {
        "id": "FU2E0CMhTC5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ozws1O90FzdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-cs1ne9S4iE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4kPjIeYzUc4",
        "outputId": "8b79df7a-0cbf-4c3a-f732-df807ce93af7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HalvingGridSearchCV(aggressive_elimination=True,\n",
            "                    cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
            "                    estimator=Pipeline(steps=[('pre',\n",
            "                                               Pipeline(memory=Memory(location=cache_shared/joblib),\n",
            "                                                        steps=[('prep',\n",
            "                                                                ColumnTransformer(sparse_threshold=1.0,\n",
            "                                                                                  transformers=[('num',\n",
            "                                                                                                 Pipeline(memory=Memory(location=cache_shared/joblib),\n",
            "                                                                                                          steps=[('imp',\n",
            "                                                                                                                  Si...\n",
            "                                               NeuralNetBinaryClassifier(_params_to_validate={'iterator_train__num_workers', 'iterator_valid__num_workers', 'iterator_train__pin_memory', 'optimizer__nesterov', 'criterion__pos_weight', 'iterator_valid__pin_memory', 'optimizer__momentum', 'iterator_train__shuffle'}, batch_size=2048, callbacks=[<skorch.callbacks.training.EarlyStopping object at 0x7f3fa8c5aea0>], compile=False, criterion__pos_weight=tensor([1.6031]), dataset=<class 'skorch.dataset.Dataset'>, device='cpu', iterator_train=<class 'torch.utils.data.dataloader.DataLoader'>, iterator_train__num_workers=0, iterator_train__pin_memory=False, iterator_train__shuffle=True, iterator_valid=<class 'torch.utils.data.dataloader.DataLoader'>, iterator_valid__num_workers=0, iterator_valid__pin_memory=False, lr=0.01, max_epochs=15, module=<class '__main__.MLP'>, optimizer=<class 'torch.optim.sgd.SGD'>, optimizer__momentum=0.0, optimizer__nesterov=False, predict_nonlinearity='auto', torch_load_kwargs=None, train_split=None, use_caching='auto', verbose=1, warm_start=False))]),\n",
            "                    factor=4, max_resources=95687, min_resources=19137,\n",
            "                    n_jobs=1,\n",
            "                    param_grid={'clf__batch_size': [2048],\n",
            "                                'clf__module__hidden': [(1024, 128),\n",
            "                                                        (216, 216, 216, 216,\n",
            "                                                         216)],\n",
            "                                'clf__optimizer__lr': [0.1, 0.5, 1],\n",
            "                                'clf__optimizer__weight_decay': [0.0001,\n",
            "                                                                 0.001]},\n",
            "                    scoring='roc_auc', verbose=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ib8RQpgupJk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}